---
title: "2.3 Prob Model for PCR Positivity Estimation"
format: html
editor: visual
---

## Quarto

Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see <https://quarto.org>.

The aim of this qmd file is providing an alternative way to monitor the severity of the outbreak. Besides of cumulative incidence in a certain time interval (like 3 months) we build a probabilistic model to estimate the prob of having a positive PCR test results in last three months. Those two are similar and we can use prob(inf. in past 3-month) to estimate the 3-month rolling incidence.

By calculating monthly average of the prob(PCR+ in past 3 months) we got an estimation in each month. By linking all those dots together we got a curve, suggesting the changing of severity of the pandemic overtime.

## Running Code

## Load packages

```{r}
library(dplyr)         # Data management
library(ggplot2)       # ggplot2
library(ggpubr)        # ggplot2 QQ plot for normality check
library(zoo)           # year-month format
library(lmtest)        # for LR test, comparing models
#library(reshape2)     # for melt() function
library(readxl)        # for reading .xlsx data
library(nnet)          # for multinomial log regression
#library(expss)         # for labeling variables
library(ggExtra)       # for marginal dist on ggplot
```

## Load dataset

```{r}
# The CBS full data
load(file = "../1_data/private/CBS.RData")
table(CBS$province, useNA = 'ifany')

# The CBSs data, for prob model only
load(file = "../1_data/private/CBSs.RData")

# The APL data
load(file = "../1_data/private/RFD4682e.RData")

# The cleaned ver of Canpath data

```

## Dataset from previous studies for model building

```{r}
## Data-01:France Leon, for negative ref, use non-reactive samples before week 69 (Oct 2020)
library(readxl)
X1_pone <- read_excel("../1_data/private/Prob Model/1-pone.xlsx", 
    sheet = "ST1_Dataset", col_types = c("numeric", 
        "text", "numeric", "numeric", "numeric", 
        "numeric", "text", "text", "text", 
        "text", "text", "text", "text", "text", 
        "text", "text", "text", "text", "text", 
        "text", "text", "text", "text", "text", 
        "text", "text", "text"))
dta_01<-select(X1_pone, 1:7, 27)
dta_01s<-dta_01[dta_01$Result=="NonReac" &
                dta_01$`Donation type`!="Convalescent plasma" &
                dta_01$`Donation Week`<69,]

# keep only assay, age, sex
dta_01s<-select(dta_01s, 1,5,6,7)
colnames(dta_01s)<-c("roche_n", "pid", "age", "gender")
tb1<-as.data.frame(table(dta_01s$pid))
colnames(tb1)<-c("pid","freq")
tb1$sample_wt<-1/tb1$freq
dta_01s<-merge(dta_01s, select(tb1, 1,3), by="pid",all.x = T, all.y = F)

## add interp var and study ID
dta_01s$study<-rep(1, length(dta_01s$pid))
dta_01s$time_pso<-rep("never_inf", length(dta_01s$pid))
rm(tb1, tb2, X1_pone)
```

```{r}
## Data-03, pre-Covid negative ref only, from Jamaica (Carribean)
X3_mmc2 <- read_excel("../1_data/private/Prob Model/3-mmc2.xlsx", 
    range = "A2:M124", na = "NT")
dta_03<-select(X3_mmc2, 2,6)
dta_03$pid<-c(1:length(dta_03$`Elecsys Index Value`))
dta_03$study<-rep(3, length(dta_03$pid))
dta_03$time_pso<-rep("never_inf", length(dta_03$pid))

dta_03s<-dta_03[!(is.na(dta_03$`Elecsys Index Value`) &
                  is.na(dta_03$`Architect IgG Index Value`)),]

# add weights
dta_03s$sample_wt<-rep(1, length(dta_03s$pid))

# correct var names
colnames(dta_03s)<-c("roche_n", "abbott_n",
                     colnames(dta_03s[,3:6]))
rm(X3_mmc2)
```

```{r}
## Data-04, 2/8 months data PSO, extracted from Y. Nagakama et al.
## The Convalescent pts data
X4_Nakagama_all <- read_excel("../1_data/private/Prob Model/4-anonymized_rocheabbott.xlsx",
                              col_types = c("numeric", "text", "numeric", 
                                            "numeric", "numeric", "numeric"))
    
dta_04<-X4_Nakagama_all

# correct col names
colnames(dta_04)<-c("age","gender","month_pso","abbott_n","roche_n","pid")
dta_04$pso <- dta_04$month_pso*30
hist(dta_04$pso, breaks = seq(0,540, by=30)) # not so much samples within 3-9 months

dta_04$time_pso[dta_04$pso<=90]<-"less_3_month"
dta_04$time_pso[dta_04$pso<=180 & dta_04$pso>90]<-"3-6_month"
dta_04$time_pso[dta_04$pso<=270 & dta_04$pso>180]<-"6-9_month"
dta_04$time_pso[dta_04$pso>270]<-"more_9_month"
table(dta_04$time_pso, useNA = 'ifany')

# All participants been sampled only once, wt=1
dta_04$sample_wt<-rep(1, length(dta_04$pid))
dta_04$study<-rep(4, length(dta_04$pid))

# clean the unused data
rm(X4_Nakagama_all)
```

```{r}
## The negative control data, updated on 7-Apr-2024
dta_04_neg <- read_excel("../1_data/private/Prob Model/4-anonymized_rocheabbott.xlsx",
                              sheet = "true_neg",
                              col_types = c("text", "numeric", "numeric", 
                                            "numeric", "numeric", "numeric"))

# correct col names
colnames(dta_04_neg)<-c("gender","age","month_pso","abbott_n","roche_n","pid")
dta_04_neg$pso <- dta_04_neg$month_pso*30

# All participants been sampled only once, wt=1
dta_04_neg$sample_wt<-rep(1, length(dta_04_neg$pid))
dta_04_neg$study<-rep(4.1, length(dta_04_neg$pid))
```


```{r}
## Data-06, shared by Dr Paul Bieniasz
X6_Paul <- read_excel("../1_data/private/Prob Model/6-2024_02_06_SR1407_McGill.xlsx", 
    sheet = "data_import", skip = 1)
dta_06<-select(X6_Paul, 1:6, 9)
colnames(dta_06)<-c("age", "gender", "pid", "pso",
                    "abbott_n", "roche_n", "study")
dta_06s<-dta_06[!(is.na(dta_06$abbott_n) &
                  is.na(dta_06$roche_n)),]

# add time_pso based on time
dta_06s$time_pso[dta_06s$pso<=90]<-"less_3_month"
dta_06s$time_pso[dta_06s$pso<=180 & dta_06s$pso>90]<-"3-6_month"
dta_06s$time_pso[dta_06s$pso<=270 & dta_06s$pso>180]<-"6-9_month"
dta_06s$time_pso[dta_06s$pso>270]<-"more_9_month"
table(dta_06s$time_pso, useNA = 'ifany')
hist(dta_06s$pso, breaks = seq(0,540, by=30)) # some data from month 3-9

# add weights
tb1<-as.data.frame(table(dta_06s$pid))
colnames(tb1)<-c("pid","freq")
tb1$sample_wt<-1/tb1$freq
dta_06s<-merge(dta_06s, select(tb1, 1,3), by="pid",all.x = T, all.y = F)
rm(tb1, tb2, X6_Paul)
```

#### bind all those four data by rows

```{r}
dta_all<-dplyr::bind_rows(dta_01s, dta_03s, 
                          select(dta_04, -c("month_pso")), dta_06s)
dta_all<-dplyr::bind_rows(dta_all, 
                          select(dta_04_neg, -c("month_pso")))

# add log quant assay (log_e transformation)
dta_all$log_roche_n<-log(dta_all$roche_n)    # COI for log_n = 0
dta_all$log_abbott_n<-log(dta_all$abbott_n)  # COI for log_n = 0.3365 (COI = 1.4)

# clean the gender var
table(dta_all$gender)
dta_all$gender[dta_all$gender %in% c("m")]<-"M"
dta_all$gender[dta_all$gender %in% c("f")]<-"F"

# Label the study var
dta_all$study<-as.character(dta_all$study)
dta_all$study[dta_all$study=='1']<-"Leon_FR"
dta_all$study[dta_all$study=='3']<-"Jamaica"
dta_all$study[dta_all$study=='4']<-"Osaka_JP_pos"
dta_all$study[dta_all$study=='4.1']<-"Osaka_JP_neg"
dta_all$study[dta_all$study=='6']<-"UK"

dta_all$time_pso[is.na(dta_all$time_pso)]<-"never_inf"

# save the rbinded harmonized data
save(dta_all, file="../1_data/private/Prob Model/dta_all.RData")

# summary analysis
hist(dta_all$pso, breaks = seq(0,540, by=30))
table(dta_all$time_pso, useNA = 'ifany')

# remove all intermediate data
rm(dta_01, dta_01s, dta_03, dta_03s, dta_04, dta_04_neg, dta_06, dta_06s)
```

##============================ Part I. Probablistic Model ====================##

#### 1.1 Multinomial Regression Model (Roche):

```{r}
# Model 01: simple model, unweighted
mnlm01<-multinom(relevel(as.factor(time_pso), ref = "never_inf") ~ roche_n, data = dta_all)
summary(mnlm01)

(summary(mnlm01))$coeffcients/summary(mnlm01)$standard.errors

# Model 02: takes sample weights into account
mnlm02<-multinom(relevel(as.factor(time_pso), ref = "never_inf") ~ roche_n, 
                 data = dta_all, weights = sample_wt)
summary(mnlm02)
```

Notes on sample weights: About the target population estimates we have in the study, it is "the proportion of being infected in past 3 months" at a certain time point (each month). So, we can regard it as a point prevalence of the target population. In this case, samples sampled at different months should be unweighted as they contributed independently to each month's point prevalence estimates.

As for the models we have been working on recently, it's a little bit different. The data we used are longitudinal but we used it in a cross-sectional manner: we pooled the data from all time point together then used quant assay data predicting the probability of being infected in the past three months. In this case, we should apply weights. Otherwise, individuals who were sampled multiple times would disproportionately influence the model parameter estimates, so they need to be downweighted."

```{r}
# model 03: using log-transformed assay

# check the distribution of roche_n (<COI)
ggdensity(dta_all$roche_n[dta_all$roche_n<1])     # mostly normal, but skewed
ggqqplot(dta_all$roche_n[dta_all$roche_n<1])      # same above
shapiro.test(dta_all$roche_n[dta_all$roche_n<1])  # not normal

# check the distribution of log_e roche_n (<COI)
ggdensity(dta_all$log_roche_n[dta_all$log_roche_n<0])     # mostly normal, but skewed
ggqqplot(dta_all$log_roche_n[dta_all$log_roche_n<0])      # same above
shapiro.test(dta_all$log_roche_n[dta_all$log_roche_n<0])  # not normal

# what if log-10 transformed
shapiro.test(log10(dta_all$roche_n[dta_all$roche_n<1]))

# check the positive cases roche-n
ggdensity(dta_all$roche_n[dta_all$roche_n>1])     # mostly normal, but skewed
ggqqplot(dta_all$roche_n[dta_all$roche_n>1])      # same above
shapiro.test(dta_all$roche_n[dta_all$roche_n>1])  # not normal

# log-e transformed, >COI
ggdensity(dta_all$log_roche_n[dta_all$log_roche_n>0])     # mostly normal, but skewed
ggqqplot(dta_all$log_roche_n[dta_all$log_roche_n>0])      # same above
shapiro.test(dta_all$log_roche_n[dta_all$log_roche_n>0])  # not normal
```

```{r}
# Model 03  takes sample weights into account
mnlm03<-multinom(relevel(as.factor(time_pso), ref = "never_inf") ~ log_roche_n, 
                 data = dta_all, weights = sample_wt)
summary(mnlm03)
## use estimates/SE and 1.96 to calculate p-value manually, should be <0.001
```

#### 1.2 Model mnlm04 same model but for abbott
```{r}
# Model 04  takes sample weights into account
mnlm04<-multinom(relevel(as.factor(time_pso), ref = "never_inf") ~ log_abbott_n, 
                 data = dta_all, weights = sample_wt)
summary(mnlm04)
## use estimates/SE and 1.96 to calculate p-value manually, should be <0.001
```



##====================== Part II. Applying the model to Sero data =============##

#### 2.1 Model adjusting for age and sex

The multinominal model we applied to APL before (mnlm01, 02, 03), none of those three model has adjusted for covariates. However with the data we have we could adjust for those two variables in Roches assays.

This subsection is to compare two models, one with age & sex adjusted and another one adjusted for nothing (mnlm03). To make two models comparable we will only use the subset with only age&sex data available

```{r}
mnlm03.a<-multinom(relevel(as.factor(time_pso), ref = "never_inf") ~ log_roche_n, 
                 data = dta_all[!is.na(dta_all$age) & 
                                !is.na(dta_all$gender),], 
                 weights = sample_wt)
summary(mnlm03.a)

mnlm03.b<-multinom(relevel(as.factor(time_pso), ref = "never_inf") ~ log_roche_n + 
                     age + gender, 
                 data = dta_all[!is.na(dta_all$age) & 
                                !is.na(dta_all$gender),], 
                 weights = sample_wt)
summary(mnlm03.b)

lrtest(mnlm03.a, mnlm03.b)
```

```{r}
# what about adding age & sex seperately?
mnlm03.b_age<-multinom(relevel(as.factor(time_pso), ref = "never_inf") ~ log_roche_n + 
                     age, 
                 data = dta_all[!is.na(dta_all$age) & 
                                !is.na(dta_all$gender),], 
                 weights = sample_wt)
summary(mnlm03.b_age)
lrtest(mnlm03.b_age, mnlm03.b)

mnlm03.b_sex<-multinom(relevel(as.factor(time_pso), ref = "never_inf") ~ log_roche_n + 
                     gender, 
                 data = dta_all[!is.na(dta_all$age) & 
                                !is.na(dta_all$gender),], 
                 weights = sample_wt)
summary(mnlm03.b_sex)
lrtest(mnlm03.b_sex, mnlm03.b)
```

**Conclusion**: 1.Adjusting for age and gender does not improve the model fit significantly. 2.Adjusting for gender only will have limited improvement on model fit. Not adjusting for age & sex is okay, it will allow us to utilize more neg ref data, as age & sex info is usually missing in those data.

#### 2.2 Apply Model (Roche) to CBS Data

```{r}
# Add log roche_n to the CBS data
CBS$log_roche_n<-log(CBS$roche_n)

CBS_prob_r<-as.data.frame(predict(mnlm03, newdata = CBS, "probs")) # num of >3 months = 0
mean(CBS_prob_r[,1], na.rm = T)  # never: 59.82%
mean(CBS_prob_r[,4], na.rm = T)  # <3 months: 25.31%
mean(CBS_prob_r[,2], na.rm = T)  # 3-6 month: 3.87%
mean(CBS_prob_r[,3], na.rm = T)  # 6-9 months: 2.98%
mean(CBS_prob_r[,5], na.rm = T)  # >9 months: 8.02%

CBS_prob_r$ever_inf <- 1-CBS_prob_r$never_inf
CBS_prob_r$less_6_month <- CBS_prob_r$less_3_month + CBS_prob_r$`3-6_month`
CBS_prob_r$less_9_month <- CBS_prob_r$less_6_month + CBS_prob_r$`6-9_month`

CBSs<-cbind.data.frame(select(CBS, pid, sampledate, sex, age, fsa,
                        province, roche_n, abbott_n, roche_s, log_roche_n),
                 CBS_prob_r[,c(4,6,7,8)])
```

```{r}
## Applying the model with age & sex
CBS$gender<-CBS$sex

CBS_prob_r2<-as.data.frame(predict(mnlm03.b, newdata = CBS, "probs")) # num of >3 months = 0
mean(CBS_prob_r2[,1], na.rm = T)  # 59.49%
mean(CBS_prob_r2[,2], na.rm = T)  # 32.45%
mean(CBS_prob_r2[,3], na.rm = T)  # 8.06%

CBSs2<-cbind.data.frame(select(CBS, pid, sampledate, sex, age, fsa,
                        province, roche_n, abbott_n, roche_s, log_roche_n),
                 CBS_prob_r2)
```

#### 2.2.2 Make by Region Plots

```{r}
# Recategorize by regions
table(CBSs$province)

# 12 provinces, recatgorized into six regions
# region divided according to Yuan's study. In CBS data since the number of samples from QC and North prov are too small (N=13, 85+83). We decided to exclude samples from those two prov from analysis.
# Also, since APL provides AB data only, we will divide prairie prov into AB and SKS+MN. This should apply to Canpath data as well.


CBSs$region<-rep(NA, length(CBSs$pid))
CBSs$region[CBSs$province %in% c("NL", "PE", "NS", "NB")]<-"Atlantic"
CBSs$region[CBSs$province %in% c("ON")]<-"Ontario"
CBSs$region[CBSs$province %in% c("AB")]<-"Alberta"
CBSs$region[CBSs$province %in% c("MB", "SK")]<-"SK & MB"
CBSs$region[CBSs$province %in% c("BC")]<-"BC"

# In this way, QC, NU/NT, and YT will be coded as 'NA'
table(CBSs$province, CBSs$region, useNA = 'ifany')

# Creat sampling months
CBSs$samplemonth<-as.yearmon(CBSs$sampledate)
table(CBSs$samplemonth, useNA = 'ifany')

# Copy new vars to CBSs2
CBSs2$region<-CBSs$region
CBSs2$samplemonth<-CBSs$samplemonth
```

#### Save the dataset

```{r}
save(CBSs, file='../1_data/private/CBSs.RData')
```

#### Creating melt data

```{r}
# create by-month est for each region
tb_bc<-CBSs[CBSs$region=="BC",] %>%
  group_by(samplemonth) %>%
  summarise(n = n() , ever_inf= mean(ever_inf, na.rm = T), 
            less_3_month=mean(less_3_month, na.rm = T))
tb_bc$region<-rep("BC", length(tb_bc$n))

tb_at<-CBSs[CBSs$region=="Atlantic",] %>%
  group_by(samplemonth) %>%
  summarise(n = n() , ever_inf= mean(ever_inf, na.rm = T), 
            less_3_month=mean(less_3_month, na.rm = T))
tb_at$region<-rep("Atlantic", length(tb_at$n))

tb_on<-CBSs[CBSs$region=="Ontario",] %>%
  group_by(samplemonth) %>%
  summarise(n = n() , ever_inf= mean(ever_inf, na.rm = T), 
            less_3_month=mean(less_3_month, na.rm = T))
tb_on$region<-rep("Ontario", length(tb_on$n))

tb_ab<-CBSs[CBSs$region=="Alberta",] %>%
  group_by(samplemonth) %>%
  summarise(n = n() , ever_inf= mean(ever_inf, na.rm = T), 
            less_3_month=mean(less_3_month, na.rm = T))
tb_ab$region<-rep("Alberta", length(tb_ab$n))

tb_skm<-CBSs[CBSs$region=="SK & MB",] %>%
  group_by(samplemonth) %>%
  summarise(n = n() , ever_inf= mean(ever_inf, na.rm = T), 
            less_3_month=mean(less_3_month, na.rm = T))
tb_skm$region<-rep("SK & MB", length(tb_skm$n))


tb_all<-rbind.data.frame(tb_bc, tb_ab, tb_skm, tb_on, tb_at)
# clean NA's
tb_all<-tb_all[!is.na(tb_all$samplemonth),]
```

```{r}
# create by-month est for each region, using CBSs2 data (model w age & sex)
tb_bc<-CBSs2[CBSs2$region=="BC",] %>%
  group_by(samplemonth) %>%
  summarise(n = n() , ever_inf= mean(ever_inf, na.rm = T), 
            less_3_month=mean(less_3_month, na.rm = T))
tb_bc$region<-rep("BC", length(tb_bc$n))

tb_at<-CBSs2[CBSs2$region=="Atlantic",] %>%
  group_by(samplemonth) %>%
  summarise(n = n() , ever_inf= mean(ever_inf, na.rm = T), 
            less_3_month=mean(less_3_month, na.rm = T))
tb_at$region<-rep("Atlantic", length(tb_at$n))

tb_on<-CBSs2[CBSs2$region=="Ontario",] %>%
  group_by(samplemonth) %>%
  summarise(n = n() , ever_inf= mean(ever_inf, na.rm = T), 
            less_3_month=mean(less_3_month, na.rm = T))
tb_on$region<-rep("Ontario", length(tb_on$n))

tb_ab<-CBSs2[CBSs2$region=="Alberta",] %>%
  group_by(samplemonth) %>%
  summarise(n = n() , ever_inf= mean(ever_inf, na.rm = T), 
            less_3_month=mean(less_3_month, na.rm = T))
tb_ab$region<-rep("Alberta", length(tb_ab$n))

tb_skm<-CBSs2[CBSs2$region=="SK & MB",] %>%
  group_by(samplemonth) %>%
  summarise(n = n() , ever_inf= mean(ever_inf, na.rm = T), 
            less_3_month=mean(less_3_month, na.rm = T))
tb_skm$region<-rep("SK & MB", length(tb_skm$n))


tb_all2<-rbind.data.frame(tb_bc, tb_ab, tb_skm, tb_on, tb_at)
# clean NA's
tb_all2<-tb_all2[!is.na(tb_all2$samplemonth),]
```

```{r}
# create by-month estimates, by region
# create by-month est for each region
tb_all<-CBSs %>%
  group_by(samplemonth, region) %>%
  summarise(n = n() , 
            ever_inf= mean(ever_inf, na.rm = T), 
            less_3_month=mean(less_3_month, na.rm = T),
            less_6_month=mean(less_6_month, na.rm=T),
            less_9_month=mean(less_9_month, na.rm=T),
            )
# clean NAs
tb_all<-tb_all[!is.na(tb_all$region), ]
```
#### 2.2.3 Make plots by region

```{r}
# Reshape meltted data
tb_melt<-reshape2::melt(select(tb_all, 1:2,4:7), 
                        id.vars = c("samplemonth", "region"),
                        variable.name = "inf",
                        value.name = "prop")

tb_melt2<-reshape2::melt(select(tb_all2, 1,3:5), 
                        id.vars = c("samplemonth", "region"),
                        variable.name = "inf",
                        value.name = "prop")

# 1. The figure using simple model
p01<-tb_melt %>%
  ggplot(aes(x=samplemonth, y=prop, group=inf, colour=inf)) +
  geom_point(aes(colour=inf)) +
  geom_line(aes(colour=inf))  +
  theme_bw() 

p01 + facet_wrap(~region)

# 2. The model using simple model + age & sex
p02<-tb_melt2 %>%
  ggplot(aes(x=samplemonth, y=prop, group=inf, colour=inf)) +
  geom_point(aes(colour=inf)) +
  geom_line(aes(colour=inf))  +
  theme_bw() 

p02 + facet_wrap(~region)
```

#### 2.3 Apply model to APL data

#### 2.3.1 Load & Clean
```{r}
summary(RFD4682_e$N)
# The codebook does not specify what types of anti-N assay is applied, given the value we assume they are using Abbott anti-N assay (small numbers)

# create a subset of APL
APLs<-RFD4682_e %>%
  select(order_ID, AGE_AT_COLLECTION, GENDER, N, `N-IgG_INTERP`, Col_Month, PAT3)

# unify colnames
colnames(APLs)<-c("order_ID","age","gender","abbott_n", "pos_abbott","samplemonth","fsa")
APLs$samplemonth<-as.yearmon(APLs$samplemonth)

# add log_abbott_n
## find 0 values bf transformation
APLs$abbott_n[APLs$abbott_n==0 & 
              !is.na(APLs$abbott_n)]<-0.001

APLs$log_abbott_n <- log(APLs$abbott_n)
```

#### 2.3.2 Apply model (Abbott)
```{r}
# Apply the model mnlm04
APLs_prob_r<-as.data.frame(predict(mnlm04, newdata = APLs, "probs")) # num of >3 months = 0
mean(APLs_prob_r[,1], na.rm = T)  # never: 53.28%
mean(APLs_prob_r[,4], na.rm = T)  # <3 months: 24.21%
mean(APLs_prob_r[,2], na.rm = T)  # 3-6 month: 5.40%
mean(APLs_prob_r[,3], na.rm = T)  # 6-9 months: 4.66%
mean(APLs_prob_r[,5], na.rm = T)  # >9 months: 12.46%

APLs_prob_r$ever_inf <- 1-APLs_prob_r$never_inf
APLs_prob_r$less_6_month <- APLs_prob_r$less_3_month + APLs_prob_r$`3-6_month`
APLs_prob_r$less_9_month <- APLs_prob_r$less_6_month + APLs_prob_r$`6-9_month`

APLs<-cbind.data.frame(APLs, APLs_prob_r[,c(4,6,7,8)])
```

```{r}
# create melt data (monthly rolling inc prop estimates)
tb_APL<-APLs %>%
  group_by(samplemonth) %>%
  summarise(n = n() , 
            ever_inf= mean(ever_inf, na.rm = T), 
            less_3_month=mean(less_3_month, na.rm = T),
            less_6_month=mean(less_6_month, na.rm=T),
            less_9_month=mean(less_9_month, na.rm=T),
            )
# clean NAs
tb_APL<-tb_APL[!is.na(tb_APL$samplemonth) & !is.na(tb_APL$ever_inf), ]


```

#### 2.3.3 making Plots
```{r}
tb_melt_APL<-reshape2::melt(select(tb_APL, 1,3:6), 
                        id.vars = c("samplemonth"),
                        variable.name = "inf",
                        value.name = "prop")

p06<-tb_melt_APL %>%
  ggplot(aes(x=samplemonth, y=prop, group=inf, colour=inf)) +
  geom_point(aes(colour=inf)) +
  geom_line(aes(colour=inf))  +
  theme_bw()
p06
```
**Additional plotting** 
```{r}
# merge monthly summary table: CBS + APL
tb_CBS<-tb_all[tb_all$region=="Alberta",] %>%
  select(-2)
tb_CBS$data<-rep("CBS", length(tb_CBS$samplemonth))

tb_APL$data<-rep("APL", length(tb_APL$samplemonth))
tb_APLCBS<-bind_rows(select(tb_CBS, -2), select(tb_APL, -2))

```

```{r}
# create melt data:
tb_melt_2<-reshape2::melt(tb_APLCBS, 
                        id.vars = c("samplemonth", "data"),
                        variable.name = "inf",
                        value.name = "prop")

p07<-tb_melt_2 %>%
  ggplot(aes(x=samplemonth, y=prop, group=data, colour=data)) +
  geom_point(aes(colour=data)) +
  geom_line(aes(colour=data))  +
  theme_bw()
p07 + facet_wrap(~inf)
```


#### 2.4 Apply model to CANPATH data

```{r}
Canpath <- read.csv("~/COVID-assay-adjust-methods/1_data/private/CANPATH/DAO-543759_ResearcherDataset_Serology_Results_74503par.csv")
Canpath_all <- read.csv("~/COVID-assay-adjust-methods/1_data/private/CANPATH/DAO-543759_ResearcherDataset_Qx_96014par_1125var.csv")

table(Canpath$C1_CITF_ASSAY_ID)
```

##===================== Part III. Exp: Reg Model Abbott N~Roche N =============##

This idea came from Alton, we can use the data we have for prob model training to generate another model: Abbott-N~Roche-N. Then apply the model to the CBS data and generate the sero-prevalence curve, see if it gets closer to the APL curve

#### 3.1.1 The linear (log) model: Abbott ~ Roche
```{r}
# The linear model using log_e transformed abbott_n and roche_n

# lm01, simple model
lm01<-glm(log_abbott_n ~ log_roche_n, 
          family = "gaussian",
          data = dta_all[!is.na(dta_all$age) &
                         !is.na(dta_all$gender),], weights = sample_wt)
summary(lm01) # AIC=1398

# lm02, add age and sex
lm02<-glm(log_abbott_n ~ log_roche_n + age + gender, 
          family = "gaussian",
          data = dta_all[!is.na(dta_all$age) &
                         !is.na(dta_all$gender),], weights = sample_wt)
summary(lm02) # AIC=1401.1, increased a bit

# lm02.a, add age only
lm02.a<-glm(log_abbott_n ~ log_roche_n + age, 
          family = "gaussian",
          data = dta_all[!is.na(dta_all$age) &
                         !is.na(dta_all$gender),], weights = sample_wt)
summary(lm02.a) # AIC=1400, increased a bit

# lm02.b, add sex only
lm02.b<-glm(log_abbott_n ~ log_roche_n + gender, 
          family = "gaussian",
          data = dta_all[!is.na(dta_all$age) &
                         !is.na(dta_all$gender),], weights = sample_wt)
summary(lm02.b) # AIC=1399.1, increased a bit

lrtest(lm02, lm01) # p=0.65, not so much diff

## Let's just use simple model lm01 then

# refit model 01, using those with missing age/sex info
lm01<-glm(log_abbott_n ~ log_roche_n, 
          family = "gaussian",
          data = dta_all, weights = sample_wt)
summary(lm01) 
```

#### 3.1.2  The linear (log) model: Roche ~ Abbott
```{r}
lm01r<-glm(log_roche_n ~ log_abbott_n, 
          family = "gaussian",
          data = dta_all, weights = sample_wt)
summary(lm01r) 
```


#### 3.2.1 Apply the model lm01 to the CBS data
```{r}
log_abbott_n<-predict(lm01, newdata = CBSs, "response")
summary(log_abbott_n)

CBSs$log_abbott_n <- log_abbott_n
CBSs$abbott_n_hat <- exp(CBSs$log_abbott_n)
summary(CBSs$abbott_n_hat)

abbott_n<-CBSs %>%
  select(abbott_n, abbott_n_hat) %>%
  .[is.na(.$abbott_n)==F,]

plot(abbott_n$abbott_n, abbott_n$abbott_n_hat)
# do a paired t-test
t.test(abbott_n$abbott_n, abbott_n$abbott_n_hat,
       paired = TRUE)
# paired t-test, log transformed
abbott_n$log_abbott_n<-log(abbott_n$abbott_n)
abbott_n$log_abbott_n_hat<-log(abbott_n$abbott_n_hat)
t.test(abbott_n$log_abbott_n, abbott_n$log_abbott_n_hat,
       paired = TRUE)

# Apply COI=1.4
CBSs$pos_abbott<-if_else(CBSs$abbott_n_hat<=1.4, 0, 1, missing = NA)
# Apply Roche COI=1.0
CBSs$pos_roche<-if_else(CBSs$roche_n<=1, 0, 1, missing = NA)
```

#### 3.2.2 Apply model lm01r to APL data
```{r}
APLs$log_roche_n<-predict(lm01r, newdata = APLs, "response")

APLs$roche_n_hat <- exp(APLs$log_roche_n)
summary(APLs$roche_n_hat)

# Apply Roche COI=1.0
APLs$pos_roche<-if_else(APLs$roche_n_hat<=1, 0, 1, missing = NA)
# recode Abbott pos as num
APLs$pos_abbott[APLs$pos_abbott=="Negative"]<-0
APLs$pos_abbott[APLs$pos_abbott=="Positive"]<-1
APLs$pos_abbott<-as.numeric(APLs$pos_abbott)
```

#### 3.3.1 plot: sero-prevalence, using predicted Abbott positivity
```{r}
tb_abb<-CBSs %>%
  group_by(samplemonth, region) %>%
  summarise(n = n() , 
            pos_abbott= sum(pos_abbott, na.rm = T), 
            pos_roche= sum(pos_roche, na.rm = T)
            )
tb_abb$prop.abbott<-tb_abb$pos_abbott/tb_abb$n
tb_abb$prop.roche<-tb_abb$pos_roche/tb_abb$n

# clean NAs
tb_abb<-tb_abb[!is.na(tb_abb$region), ]

tb_abb_melt<-reshape2::melt(select(tb_abb, 1:2,6:7), 
                        id.vars = c("samplemonth", "region"),
                        variable.name = "assay",
                        value.name = "prop")

p03<-tb_abb_melt %>%
  ggplot(aes(x=samplemonth, y=prop, group=assay, colour=assay)) +
  geom_point(aes(colour=assay)) +
  geom_line(aes(colour=assay))  +
  theme_bw() 

p03 + facet_wrap(~region)
```

#### 3.3.2 plot: sero-prevalence, using predicted Roche pos
```{r}
tb_ro<-APLs %>%
  group_by(samplemonth) %>%
  summarise(n = n() , 
            pos_abbott= sum(pos_abbott, na.rm = T), 
            pos_roche= sum(pos_roche, na.rm = T)
            )
tb_ro$prop.abbott<-tb_ro$pos_abbott/tb_ro$n
tb_ro$prop.roche<-tb_ro$pos_roche/tb_ro$n

# clean NAs
tb_ro<-tb_ro[!is.na(tb_ro$samplemonth) & 
             !tb_ro$pos_abbott==0, ]

tb_ro_melt<-reshape2::melt(select(tb_ro, -c(2:4)), 
                        id.vars = c("samplemonth"),
                        variable.name = "assay",
                        value.name = "prop")

p03r<-tb_ro_melt %>%
  ggplot(aes(x=samplemonth, y=prop, group=assay, colour=assay)) +
  geom_point(aes(colour=assay)) +
  geom_line(aes(colour=assay))  +
  theme_bw() 
p03r
```


#### 3.4 Plot the correlation btw Roche-N and Abbott-N:
```{r}
# The clear linear relation btw log_roche and log_abbott:
plot(CBSs$log_roche_n, CBSs$log_abbott_n) # this linear association is intriduced by lm01

# How it looks like in normal scale?
plot(CBSs$roche_n, CBSs$abbott_n_hat)     # a smooth curve

dta_all$study<-as.factor(dta_all$study)

# using our training data:
p04<-dta_all %>%
  .[!is.na(.$log_abbott_n) & !is.na(.$log_roche_n),] %>%
  ggplot(aes(x=log_roche_n, y=log_abbott_n, 
             study, colour=study)) +
  geom_point(aes(colour=as.factor(study)), alpha=0.5) +
  geom_vline(xintercept = 0, linewidth=1.0, linetype="dotted", col="red") +
  geom_hline(yintercept = log(1.4), linewidth=1.0, linetype="dotted", col="red") +
  xlab("Roche Anti-N S/Co ratio (log scale)") + 
  ylab("Abbott Anti-N S/Co ratio (log scale)") +
  labs(color='') +
  scale_colour_manual(labels = c("Jamaica (-)", "Osaka, JP (-)",
                                 "Osaka, JP (+)","UK (+)"), 
                      values = c("red", "blue", "darkgreen", "purple")) +
  theme_bw() + 
  theme(legend.position = "bottom")

p04
```

```{r}
## Another figure: add CBS matched data
dta_CBS<-CBSs[!is.na(CBSs$abbott_n) & !is.na(CBSs$roche_n),]  %>%
  select(log_roche_n, abbott_n)
dta_CBS$study<-rep("CBS matched", length(dta_CBS$log_roche_n))
dta_CBS$log_abbott_n<-log(dta_CBS$abbott_n)

dta_CBS<-bind_rows(select(dta_all, study, log_roche_n, log_abbott_n), 
                   select(dta_CBS, study, log_roche_n, log_abbott_n))

p05<-dta_CBS %>%
  .[!is.na(.$log_abbott_n) & !is.na(.$log_roche_n),] %>%
  ggplot(aes(x=log_roche_n, y=log_abbott_n, 
             study, colour=study)) +
  geom_point(aes(colour=as.factor(study)), alpha=0.40) +
  geom_vline(xintercept = 0, linewidth=1.0, linetype="dotted", col="red") +
  geom_hline(yintercept = log(1.4), linewidth=1.0, linetype="dotted", col="red") +
  xlab("Roche Anti-N S/Co ratio (log scale)") + 
  ylab("Abbott Anti-N S/Co ratio (log scale)") +
  labs(color='') +
  scale_colour_manual(labels = c("CBS","Jamaica (-)", "Osaka, JP (-)",
                                 "Osaka, JP (+)","UK (+)"), 
                      values = c("lightblue","red", "blue", "darkgreen", "purple")) +
  theme_bw() + 
  theme(legend.position = "bottom")

p05
```
#### Alton suggests using marginal dist with {ggExtra}
```{r}
ggMarginal(p04, groupColour = TRUE, groupFill = TRUE) # log-scale
ggMarginal(p05, groupColour = TRUE, groupFill = TRUE) # with CBS matched data
```







## Part IV Misc Analysis

1. About the age dist in training data and CBS: The difference on age distribution might be a potential problem. Generally speaking, blood donors (CBS, FR-Leon data) is relatively older, while Covid-19 convalescent patients are younger.
```{r}
# The FR-Leon data
summary(dta_all[dta_all$study==1,]$age) # mean=46, median = 48
hist(dta_all[dta_all$study==1,]$age)

# UK - Convalscent Pts
summary(dta_all[dta_all$study==6,]$age) # mean=44.54, median = 47
hist(dta_all[dta_all$study==6,]$age, breaks = 25) # two waves?

# overall dist (FR-Leon + UK)
summary(dta_all[dta_all$study %in% c(1,6),]$age) # mean=46, median = 48
hist(dta_all[dta_all$study %in% c(1,6),]$age, breaks = 25)
# overall it looks good

# CBS
summary(CBSs$age) # one ourlier = 168, who is this??
hist(CBSs$age[CBSs$age<100])

# CBS by anti-N pos
hist(CBSs$age[CBSs$age<100 & 
              CBSs$roche_n>1])

# KS test: UK+FR-Leon vs CBS
ks.test(dta_all[dta_all$study %in% c(1,6),]$age, 
        CBSs$age[CBSs$age<100])
# as KS test suggests, the distribution of age btw two groups is different
```
```{r}
# create a sampling prob variable, based on the age dist in CBS
CBSs$age_group<-CBS$age_group

tb1<-as.data.frame(prop.table(table(CBS$age_group)))
colnames(tb1)<-c("age_group","age_w")
tb1$n_sp<-round(tb1$age_w*650, digits = 0)

dta_all$age_group[dta_all$age<20 & dta_all$age>0]<-"10-19 years"
dta_all$age_group[dta_all$age<30 & dta_all$age>20]<-"20-29 years"
dta_all$age_group[dta_all$age<40 & dta_all$age>30]<-"30-39 years"
dta_all$age_group[dta_all$age<50 & dta_all$age>40]<-"40-49 years"
dta_all$age_group[dta_all$age<60 & dta_all$age>50]<-"50-59 years"
dta_all$age_group[dta_all$age<70 & dta_all$age>60]<-"60-69 years"
dta_all$age_group[dta_all$age<80 & dta_all$age>70]<-"70-79 years"
dta_all$age_group[dta_all$age>80]<-"80+ years"
table(dta_all$age_group, useNA = 'ifany')

dta_all<-merge(dta_all, tb1, by="age_group", all.x=T, all.y=F)
```

#### Create a sample based on the sampling prob:
```{r}
# a simple prob sampling:
set.seed(2048)
dta_sp<-slice_sample(dta_all[!is.na(dta_all$age_w),], n=650,
             weight_by = dta_all[!is.na(dta_all$age_w),]$age_w,
             replace = FALSE)

# how does age looks like in the sample?
hist(dta_sp$age)

# Stratified sampling (Alternative):
dta1<-dta_all[!is.na(dta_all$age_group == "10-19 years"),] %>%
  slice_sample(n=tb1$n_sp[2], replace = FALSE)
dta2<-dta_all[!is.na(dta_all$age_group == "20-29 years"),] %>%
  slice_sample(n=tb1$n_sp[3], replace = FALSE)
dta3<-dta_all[!is.na(dta_all$age_group == "30-39 years"),] %>%
  slice_sample(n=tb1$n_sp[4], replace = FALSE)
dta4<-dta_all[!is.na(dta_all$age_group == "40-49 years"),] %>%
  slice_sample(n=tb1$n_sp[5], replace = FALSE)
dta5<-dta_all[!is.na(dta_all$age_group == "50-59 years"),] %>%
  slice_sample(n=tb1$n_sp[6], replace = FALSE)
dta6<-dta_all[!is.na(dta_all$age_group == "60-69 years"),] %>%
  slice_sample(n=tb1$n_sp[7], replace = FALSE)
dta7<-dta_all[!is.na(dta_all$age_group == "70-79 years"),] %>%
  slice_sample(n=tb1$n_sp[8], replace = FALSE)
dta8<-dta_all[!is.na(dta_all$age_group == "80+ years"),] %>%
  slice_sample(n=sum(tb1$n_sp[9:10]), replace = FALSE)
dta_sp<-rbind.data.frame(dta1, dta2, dta3, dta4, dta5,
                         dta6, dta7, dta8)
rm(dta1, dta2, dta3, dta4, dta5, dta6, dta7, dta8)

# KS test
ks.test(dta_sp$age, CBSs$age[CBSs$age<100])
```

## Regression on sampled data:
```{r}
mnlm03.s<-multinom(relevel(as.factor(time_pso), ref = "never_inf") ~ log_roche_n + 
                     age + gender, 
                 data = dta_sp,
                 weights = sample_wt)
summary(mnlm03.s)
```


